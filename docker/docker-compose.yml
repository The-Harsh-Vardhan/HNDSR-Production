# ═══════════════════════════════════════════════════════════════════════════
# HNDSR Docker Compose — Full Stack
# ═══════════════════════════════════════════════════════════════════════════
# Services:
#   1. hndsr-api     — FastAPI server (GPU)
#   2. hndsr-worker  — Redis queue worker (GPU)
#   3. redis          — Job queue and result store
#   4. nginx          — Reverse proxy (TLS, rate limiting)
#   5. prometheus     — Metrics collection
#   6. grafana        — Metrics dashboard
# ═══════════════════════════════════════════════════════════════════════════

version: "3.8"

services:

  # ── HNDSR API Server ─────────────────────────────────────────────────
  hndsr-api:
    build:
      context: ..
      dockerfile: docker/Dockerfile
    container_name: hndsr-api
    ports:
      - "8000:8000"
    environment:
      - DEVICE=auto
      - MODEL_DIR=/app/checkpoints
      - REDIS_URL=redis://redis:6379/0
      - MAX_CONCURRENT=4
      - MAX_QUEUE_DEPTH=20
      - REQUEST_TIMEOUT_S=30
      - RATE_LIMIT_PER_HOUR=100
      - MODEL_VERSION=1.0.0
    volumes:
      - model-data:/app/checkpoints
      - ./logs:/app/logs
    depends_on:
      redis:
        condition: service_healthy
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [ gpu ]
    restart: unless-stopped
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8000/health" ]
      interval: 30s
      timeout: 5s
      start_period: 60s
      retries: 3

  # ── Queue Worker (optional — for async processing) ───────────────────
  hndsr-worker:
    build:
      context: ..
      dockerfile: docker/Dockerfile
    container_name: hndsr-worker
    command: [ "python", "-m", "backend.inference_worker" ]
    environment:
      - DEVICE=auto
      - MODEL_DIR=/app/checkpoints
      - REDIS_URL=redis://redis:6379/0
      - MAX_BATCH_SIZE=4
      - BATCH_TIMEOUT_S=0.5
      - MAX_RETRIES=3
    volumes:
      - model-data:/app/checkpoints
    depends_on:
      redis:
        condition: service_healthy
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [ gpu ]
    restart: unless-stopped
    profiles:
      - worker # Only starts with: docker compose --profile worker up

  # ── Redis ────────────────────────────────────────────────────────────
  redis:
    image: redis:7-alpine
    container_name: hndsr-redis
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    command: redis-server --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru
    healthcheck:
      test: [ "CMD", "redis-cli", "ping" ]
      interval: 10s
      timeout: 3s
      retries: 5
    restart: unless-stopped

  # ── Nginx Reverse Proxy ──────────────────────────────────────────────
  nginx:
    image: nginx:alpine
    container_name: hndsr-nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - hndsr-api
    restart: unless-stopped
    profiles:
      - production

  # ── Prometheus ───────────────────────────────────────────────────────
  prometheus:
    image: prom/prometheus:v2.48.0
    container_name: hndsr-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ../observability/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ../observability/alerting_rules.yml:/etc/prometheus/alerting_rules.yml:ro
      - prometheus-data:/prometheus
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.retention.time=15d"
    restart: unless-stopped

  # ── Grafana ──────────────────────────────────────────────────────────
  grafana:
    image: grafana/grafana:10.2.0
    container_name: hndsr-grafana
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=hndsr-admin
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana-data:/var/lib/grafana
      - ../observability/grafana_dashboard.json:/var/lib/grafana/dashboards/hndsr.json:ro
    depends_on:
      - prometheus
    restart: unless-stopped

volumes:
  model-data:
    driver: local
  redis-data:
    driver: local
  prometheus-data:
    driver: local
  grafana-data:
    driver: local
