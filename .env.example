# ═══════════════════════════════════════════════════════════════
# HNDSR Production — Environment Variables
# ═══════════════════════════════════════════════════════════════
# Copy this file to .env and adjust values for your setup.
# All variables have sensible defaults; only override as needed.

# ── Inference Device ──────────────────────────────────────────
DEVICE=auto                  # auto | cuda | cpu
USE_FP16=false               # Enable FP16 mixed precision (CUDA only)

# ── Model Configuration ──────────────────────────────────────
MODEL_DIR=./checkpoints      # Path to model weight files
DDIM_STEPS=20                # Default DDIM denoising steps (20-100)
TILE_SIZE=64                 # Tile size in pixels for large images
TILE_OVERLAP=8               # Overlap between tiles (Hann blending)

# ── Server Limits ─────────────────────────────────────────────
MAX_CONCURRENT=4             # Max simultaneous GPU inferences
MAX_QUEUE_DEPTH=20           # Reject requests when queue exceeds this
REQUEST_TIMEOUT_S=120        # Per-request timeout in seconds
MAX_PAYLOAD_MB=20            # Maximum upload size in MB
MAX_IMAGE_PIXELS=16000000    # Maximum input image pixels (16M)
RATE_LIMIT_PER_HOUR=100      # Per-IP rate limit

# ── Version ───────────────────────────────────────────────────
MODEL_VERSION=1.0.0
